# Fractal Protocol v2.2: Adaptive Skeletonization

**Status:** Draft
**Author:** pm_encoder Team
**Created:** 2025-12-21
**Target Release:** rust-v2.2.0

---

## 1. Overview & Problem Statement

### 1.1 The Binary Inclusion Problem

Currently, `pm_encoder` uses a binary inclusion model for token budgeting:

```
File → [Include Full] or [Drop Entirely]
```

This creates a **context cliff** problem:

```
Scenario: Budget = 1000 tokens, 3 files @ 400 tokens each

Current Behavior:
  ✓ src/main.rs    (400 tokens) → Included
  ✓ src/config.rs  (400 tokens) → Included
  ✗ src/utils.rs   (400 tokens) → DROPPED (budget exceeded)

Result: LLM has zero awareness that utils.rs exists.
        May suggest creating functions that already exist.
        Cannot navigate to it via zoom.
```

### 1.2 The Value of Shape Awareness

**Principle:** Knowing a function *exists* is more valuable than knowing *nothing*.

A "skeleton" representation costs ~10-15% of full content but provides:

- **Existence awareness**: LLM knows the module/function exists
- **Signature knowledge**: Parameter types, return types visible
- **Navigation targets**: Can still `zoom` into skeletonized files
- **Dependency mapping**: Import statements preserved

```
Skeleton Approach:
  ✓ src/main.rs    (400 tokens) → Full
  ✓ src/config.rs  (400 tokens) → Full
  ◐ src/utils.rs   (50 tokens)  → SKELETON (signatures only)

Result: LLM knows utils.rs has helper_function(x: i32) -> String
        Can suggest: "See utils::helper_function for this logic"
        Can zoom: function=helper_function works
```

### 1.3 Inspiration

This design is inspired by:
- **CFD Protocol's HybridCFDPMSerializer**: Priority-based content reduction
- **IDE Symbol Outlines**: VS Code's document symbols view
- **API Documentation**: Showing signatures without implementations

---

## 2. Core Concepts

### 2.1 Compression Levels

The Skeleton Protocol defines four compression levels:

| Level | Name | Content | Typical Reduction |
|-------|------|---------|-------------------|
| **L0** | Full | Complete file content | 0% (baseline) |
| **L1** | Skeleton+ | Signatures + Docstrings + Constants | ~70-80% |
| **L2** | Skeleton | Signatures only | ~85-90% |
| **L3** | Drop | Excluded from output | 100% |

#### Level 0: Full Content
```rust
/// Configuration for the application
pub struct Config {
    pub host: String,
    pub port: u16,
    pub debug: bool,
}

impl Config {
    /// Load configuration from environment
    pub fn from_env() -> Result<Self, ConfigError> {
        let host = std::env::var("HOST").unwrap_or_else(|_| "localhost".to_string());
        let port = std::env::var("PORT")
            .ok()
            .and_then(|p| p.parse().ok())
            .unwrap_or(8080);
        let debug = std::env::var("DEBUG").is_ok();

        Ok(Self { host, port, debug })
    }

    /// Validate the configuration
    pub fn validate(&self) -> Result<(), ConfigError> {
        if self.port == 0 {
            return Err(ConfigError::InvalidPort);
        }
        Ok(())
    }
}
```

#### Level 1: Skeleton+ (Signatures + Docstrings)
```rust
/// Configuration for the application
pub struct Config {
    pub host: String,
    pub port: u16,
    pub debug: bool,
}

impl Config {
    /// Load configuration from environment
    pub fn from_env() -> Result<Self, ConfigError> { /* ... */ }

    /// Validate the configuration
    pub fn validate(&self) -> Result<(), ConfigError> { /* ... */ }
}
```

#### Level 2: Skeleton (Signatures Only)
```rust
pub struct Config {
    pub host: String,
    pub port: u16,
    pub debug: bool,
}

impl Config {
    pub fn from_env() -> Result<Self, ConfigError>;
    pub fn validate(&self) -> Result<(), ConfigError>;
}
```

#### Level 3: Drop
File not included in output.

### 2.2 The Skeletonizer

The `Skeletonizer` is the engine responsible for reducing file content to a target compression level.

```rust
pub struct Skeletonizer {
    /// Target compression level
    target_level: CompressionLevel,
}

pub enum CompressionLevel {
    Full,       // L0: Keep everything
    SkeletonPlus, // L1: Signatures + docstrings
    Skeleton,   // L2: Signatures only
    Drop,       // L3: Exclude file
}

impl Skeletonizer {
    /// Reduce content to target level
    pub fn skeletonize(&self, content: &str, lang: Language) -> SkeletonResult;

    /// Estimate token count after skeletonization
    pub fn estimate_tokens(&self, content: &str, lang: Language) -> usize;
}

pub struct SkeletonResult {
    pub content: String,
    pub original_tokens: usize,
    pub skeleton_tokens: usize,
    pub compression_ratio: f32,
    pub preserved_symbols: Vec<String>,
}
```

### 2.3 The Adaptive Allocator

The `AdaptiveAllocator` manages the budget by progressively downgrading files:

```
Algorithm: Adaptive Budget Allocation

Input: files[], budget, tier_priorities
Output: allocated_files[] with compression levels

1. Sort files by tier (Core > Config > Tests > Other)
2. Initial pass: assign L0 (Full) to all files
3. Calculate total_tokens

4. While total_tokens > budget:
   a. Find lowest-priority file at lowest compression level
   b. Downgrade: L0 → L1 → L2 → L3
   c. Recalculate total_tokens
   d. If file reaches L3, remove from allocation

5. Return allocated_files with final compression levels
```

**Priority Order for Downgrade:**
1. Other tier files (docs, scripts) → downgrade first
2. Tests tier files
3. Config tier files
4. Core tier files → downgrade last

---

## 3. Technical Architecture

### 3.1 Language Support Matrix

| Language | Function Pattern | Class/Struct Pattern | Docstring Pattern |
|----------|------------------|---------------------|-------------------|
| **Rust** | `(pub\s+)?(async\s+)?fn\s+\w+` | `(pub\s+)?struct\|enum\|trait\|impl` | `///` or `//!` |
| **Python** | `(async\s+)?def\s+\w+` | `class\s+\w+` | `"""..."""` or `'''...'''` |
| **TypeScript/JS** | `(async\s+)?function\s+\w+\|const\s+\w+\s*=\s*(\(|async)` | `class\s+\w+` | `/** ... */` |
| **Go** | `func\s+(\(\w+\s+\*?\w+\)\s+)?\w+` | `type\s+\w+\s+struct` | `//` preceding |

### 3.2 Regex Strategy

We use a **line-by-line state machine** approach rather than full AST parsing for performance:

```rust
pub struct SkeletonParser {
    state: ParserState,
    brace_depth: usize,
    indent_stack: Vec<usize>,  // For Python
}

enum ParserState {
    TopLevel,           // Looking for definitions
    InDocstring,        // Accumulating docstring
    InSignature,        // Multi-line signature
    InBody,             // Skipping body content
}
```

**Block Detection Strategy:**

| Language | Block End Detection |
|----------|---------------------|
| Rust/TS/JS/Go | Brace counting: `{` increments, `}` decrements, end at depth 0 |
| Python | Indentation: end when line has ≤ definition indent |

### 3.3 Struct Changes

#### FileEntry Enhancement
```rust
pub struct FileEntry {
    pub path: String,
    pub content: String,
    pub size: u64,
    pub modified: Option<SystemTime>,

    // NEW: Skeleton Protocol fields
    pub compression_level: CompressionLevel,
    pub original_tokens: usize,
    pub skeleton_content: Option<String>,  // Cached skeleton
}
```

#### BudgetStats Enhancement
```rust
pub struct BudgetStats {
    pub total_tokens: usize,
    pub files_included: usize,
    pub files_dropped: usize,

    // NEW: Skeleton tracking
    pub files_skeletonized: usize,
    pub tokens_saved_by_skeleton: usize,
    pub compression_breakdown: HashMap<CompressionLevel, usize>,
}
```

#### EncoderConfig Enhancement
```rust
pub struct EncoderConfig {
    // ... existing fields ...

    // NEW: Skeleton options
    pub skeleton_enabled: bool,
    pub min_skeleton_level: CompressionLevel,  // Don't go below this
    pub preserve_docstrings: bool,             // L1 vs L2 default
}
```

### 3.4 Output Format

Skeletonized files are marked in the output:

```
+++ src/utils.rs [SKELETON:L1]
+ /// Helper utilities for string processing
+ pub fn format_name(first: &str, last: &str) -> String { /* ... */ }
+
+ /// Parse a configuration line
+ pub fn parse_config_line(line: &str) -> Option<(String, String)> { /* ... */ }
--- src/utils.rs [md5:abc123] [original:1234 tokens → skeleton:89 tokens]
```

### 3.5 Module Structure

```
src/
├── core/
│   ├── skeleton/
│   │   ├── mod.rs           // Module exports
│   │   ├── parser.rs        // Line-by-line parser
│   │   ├── languages.rs     // Language-specific patterns
│   │   └── allocator.rs     // Adaptive budget allocator
│   └── ...
└── ...
```

---

## 4. Test Plan (TDD)

### 4.1 Unit Tests

#### 4.1.1 Regex Pattern Tests
```rust
#[test]
fn test_rust_function_signature_extraction() {
    let input = r#"
        pub fn process(data: &[u8]) -> Result<Output, Error> {
            let parsed = parse(data)?;
            transform(parsed)
        }
    "#;

    let skeleton = skeletonize(input, Language::Rust, CompressionLevel::Skeleton);
    assert_eq!(skeleton, "pub fn process(data: &[u8]) -> Result<Output, Error>;");
}

#[test]
fn test_python_class_skeleton() {
    let input = r#"
class Config:
    """Application configuration."""

    def __init__(self, path: str):
        self.path = Path(path)
        self.data = {}

    def load(self) -> dict:
        """Load configuration from file."""
        with open(self.path) as f:
            self.data = json.load(f)
        return self.data
    "#;

    let skeleton = skeletonize(input, Language::Python, CompressionLevel::SkeletonPlus);
    assert!(skeleton.contains("class Config:"));
    assert!(skeleton.contains('"""Application configuration."""'));
    assert!(skeleton.contains("def __init__(self, path: str): ..."));
    assert!(skeleton.contains("def load(self) -> dict:"));
    assert!(!skeleton.contains("json.load"));
}
```

#### 4.1.2 Brace Counting Tests
```rust
#[test]
fn test_nested_braces_rust() {
    let input = r#"
fn outer() {
    if condition {
        inner();
    }
    match x {
        A => { do_a(); }
        B => { do_b(); }
    }
}
    "#;

    let end_line = find_block_end(input, 1, Language::Rust);
    assert_eq!(end_line, 9);  // Line with final }
}

#[test]
fn test_python_indentation_tracking() {
    let input = r#"
def outer():
    if True:
        nested()

    for x in items:
        process(x)

def next_function():
    pass
    "#;

    let end_line = find_block_end(input, 1, Language::Python);
    assert_eq!(end_line, 7);  // Empty line before next_function
}
```

### 4.2 Integration Tests

#### 4.2.1 Budget Constraint Scenarios
```rust
#[test]
fn test_three_files_fit_as_skeletons() {
    let temp_dir = create_test_project_with_files(vec![
        ("src/main.rs", MAIN_CONTENT_400_TOKENS),
        ("src/config.rs", CONFIG_CONTENT_400_TOKENS),
        ("src/utils.rs", UTILS_CONTENT_400_TOKENS),
    ]);

    let config = EncoderConfig {
        token_budget: Some(1000),
        skeleton_enabled: true,
        ..Default::default()
    };

    let engine = ContextEngine::with_config(config);
    let result = engine.serialize(temp_dir.path().to_str().unwrap()).unwrap();

    // All three files should be present
    assert!(result.contains("src/main.rs"));
    assert!(result.contains("src/config.rs"));
    assert!(result.contains("src/utils.rs"));

    // At least one should be skeletonized
    assert!(result.contains("[SKELETON:"));
}

#[test]
fn test_tier_priority_in_skeleton_downgrade() {
    // Core files should be skeletonized last
    let temp_dir = create_test_project_with_files(vec![
        ("src/core.rs", CORE_CONTENT),      // Core tier
        ("tests/test.rs", TEST_CONTENT),    // Tests tier
        ("docs/readme.md", DOCS_CONTENT),   // Other tier
    ]);

    let config = EncoderConfig {
        token_budget: Some(500),
        skeleton_enabled: true,
        ..Default::default()
    };

    let result = engine.serialize(...);

    // Core should be full or L1, docs should be L2 or dropped
    assert!(result.contains("src/core.rs"));  // Should be included
    // docs/readme.md may be skeleton or dropped
}
```

#### 4.2.2 Compression Ratio Verification
```rust
#[test]
fn test_skeleton_achieves_target_compression() {
    let full_content = include_str!("fixtures/large_module.rs");
    let full_tokens = count_tokens(full_content);

    let skeleton = skeletonize(full_content, Language::Rust, CompressionLevel::Skeleton);
    let skeleton_tokens = count_tokens(&skeleton);

    let compression_ratio = 1.0 - (skeleton_tokens as f32 / full_tokens as f32);

    // Skeleton should achieve 80-95% compression
    assert!(compression_ratio >= 0.80, "Expected ≥80% compression, got {}%", compression_ratio * 100.0);
    assert!(compression_ratio <= 0.95, "Expected ≤95% compression, got {}%", compression_ratio * 100.0);
}
```

### 4.3 Snapshot Tests

```rust
#[test]
fn test_skeleton_output_format_snapshot() {
    let input = include_str!("fixtures/sample_module.rs");
    let skeleton = skeletonize(input, Language::Rust, CompressionLevel::SkeletonPlus);

    insta::assert_snapshot!("rust_skeleton_plus", skeleton);
}

#[test]
fn test_python_skeleton_snapshot() {
    let input = include_str!("fixtures/sample_module.py");
    let skeleton = skeletonize(input, Language::Python, CompressionLevel::Skeleton);

    insta::assert_snapshot!("python_skeleton", skeleton);
}
```

---

## 5. MCP Integration

### 5.1 get_context Enhancement

The `get_context` tool gains automatic skeleton behavior:

```json
{
  "name": "get_context",
  "arguments": {
    "path": "/project",
    "token_budget": "1000",
    "skeleton": "auto"  // NEW: "auto" | "enabled" | "disabled"
  }
}
```

**Skeleton Modes:**
- `"auto"` (default): Enable skeleton when budget is specified
- `"enabled"`: Always use skeleton for budget optimization
- `"disabled"`: Binary include/drop behavior

### 5.2 Response Enhancement

The response includes skeleton metadata:

```json
{
  "content": [
    {
      "type": "text",
      "text": "..."
    }
  ],
  "metadata": {
    "files_full": 5,
    "files_skeleton": 3,
    "files_dropped": 1,
    "tokens_saved": 2340,
    "compression_summary": {
      "L0": ["src/main.rs", "src/lib.rs"],
      "L1": ["src/utils.rs", "src/config.rs"],
      "L2": ["src/helpers.rs"],
      "L3": ["docs/old_notes.md"]
    }
  }
}
```

### 5.3 Zoom Interaction

Skeletonized files remain zoomable:

```json
{
  "name": "zoom",
  "arguments": {
    "target": "function=helper_function",
    "path": "/project"
  }
}
```

Even if `src/utils.rs` was included as skeleton, zooming to `helper_function` returns the **full** function content (reads directly from disk).

---

## 6. Implementation Phases

### Phase 1: Core Skeletonizer (Week 1)
- [ ] Implement `CompressionLevel` enum
- [ ] Implement `Skeletonizer` for Rust
- [ ] Add unit tests for Rust patterns
- [ ] Implement brace-counting block detection

### Phase 2: Multi-Language Support (Week 2)
- [ ] Add Python skeletonizer (indentation-based)
- [ ] Add TypeScript/JavaScript skeletonizer
- [ ] Add Go skeletonizer
- [ ] Language detection integration

### Phase 3: Adaptive Allocator (Week 3)
- [ ] Implement `AdaptiveAllocator`
- [ ] Integrate with `ContextEngine`
- [ ] Update `BudgetStats` with skeleton metrics
- [ ] Integration tests

### Phase 4: MCP & Polish (Week 4)
- [ ] Update `get_context` with skeleton parameter
- [ ] Add metadata to MCP responses
- [ ] Snapshot tests for all languages
- [ ] Documentation and examples

---

## 7. Open Questions

1. **Docstring Preservation**: Should L1 (Skeleton+) be the default, or L2 (Skeleton)?
   - L1 is more useful but larger
   - Recommendation: L1 default, with config option

2. **Constant Handling**: Should top-level constants be preserved in skeleton?
   - `const MAX_RETRIES: usize = 3;` is useful context
   - Recommendation: Preserve in L1, strip in L2

3. **Import Statements**: Preserve all imports or only used ones?
   - Full imports help understand dependencies
   - Recommendation: Preserve all imports (low token cost)

4. **Macro Handling (Rust)**: How to handle `#[derive(...)]` and other macros?
   - Recommendation: Preserve attribute macros on structs/functions

---

## 8. Success Metrics

| Metric | Target |
|--------|--------|
| Skeleton compression ratio | 80-90% token reduction |
| Files preserved vs dropped | 2x more files in output |
| Zoom success rate | 100% (skeleton files still zoomable) |
| Performance overhead | <10% additional processing time |
| Test coverage | >90% for skeleton module |

---

## Appendix A: Example Transformations

### Rust Full → Skeleton

**Input (L0):**
```rust
/// Process incoming data with validation
pub async fn process_data(
    input: &[u8],
    config: &Config,
) -> Result<ProcessedData, ProcessError> {
    let validated = validate_input(input)?;
    let parsed = parse_data(&validated)?;

    let mut result = ProcessedData::new();
    for item in parsed.items {
        if config.should_include(&item) {
            result.add(transform_item(item)?);
        }
    }

    Ok(result)
}
```

**Output (L1 - Skeleton+):**
```rust
/// Process incoming data with validation
pub async fn process_data(
    input: &[u8],
    config: &Config,
) -> Result<ProcessedData, ProcessError> { /* ... */ }
```

**Output (L2 - Skeleton):**
```rust
pub async fn process_data(input: &[u8], config: &Config) -> Result<ProcessedData, ProcessError>;
```

### Python Full → Skeleton

**Input (L0):**
```python
class DataProcessor:
    """Processes data files with configurable transformations."""

    def __init__(self, config: Config):
        """Initialize with configuration.

        Args:
            config: Processing configuration object
        """
        self.config = config
        self.cache = {}
        self._setup_handlers()

    def process(self, data: bytes) -> ProcessedData:
        """Process raw bytes into structured data.

        Args:
            data: Raw input bytes

        Returns:
            Processed and validated data structure
        """
        validated = self._validate(data)
        parsed = self._parse(validated)
        return self._transform(parsed)
```

**Output (L1 - Skeleton+):**
```python
class DataProcessor:
    """Processes data files with configurable transformations."""

    def __init__(self, config: Config):
        """Initialize with configuration."""
        ...

    def process(self, data: bytes) -> ProcessedData:
        """Process raw bytes into structured data."""
        ...
```

**Output (L2 - Skeleton):**
```python
class DataProcessor:
    def __init__(self, config: Config): ...
    def process(self, data: bytes) -> ProcessedData: ...
```

---

*Document Version: 1.0*
*Last Updated: 2025-12-21*
